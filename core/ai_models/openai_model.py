import os
import base64
import json
import logging
import asyncio
from pathlib import Path
from typing import List, Dict, Any

from openai import AsyncOpenAI, OpenAI

from .base_model import BaseGradingModel
from core.llm_logger import log_llm_call, SERVICE_VISION_GRADING

# Setup logging
logger = logging.getLogger(__name__)

class OpenAIModel(BaseGradingModel):
    """
    An implementation of the BaseGradingModel using OpenAI's GPT Vision models.
    """
    
    # The detailed prompt is now part of this model-specific implementation.
    VISION_GRADING_PROMPT = """
M·ªôt gi√°o vi√™n To√°n Vi·ªát Nam t√†i gi·ªèi v·ªõi 20 nƒÉm kinh nghi·ªám, s·ªü tr∆∞·ªùng c·ªßa b·∫°n l√† ph√¢n t√≠ch s√¢u s·∫Øc logic gi·∫£i b√†i c·ªßa h·ªçc sinh v√† ƒë∆∞a ra nh·ªØng nh·∫≠n x√©t ch√≠nh x√°c, c√¥ng t√¢m.
**IMAGES INPUT:**
1.  **·∫¢NH ƒê·ªÄ B√ÄI:** N·ªôi dung c√¢u h·ªèi.
2.  **·∫¢NH B√ÄI L√ÄM:** L·ªùi gi·∫£i vi·∫øt tay c·ªßa h·ªçc sinh.

### **TRI·∫æT L√ù V√Ä QUY TR√åNH CH·∫§M B√ÄI**
**B∆∞·ªõc 1: ƒê·ªçc Hi·ªÉu To√†n Di·ªán**
ƒê·∫ßu ti√™n, ƒë·ªçc k·ªπ **·∫¢NH ƒê·ªÄ B√ÄI**, n·∫Øm v·ªØng y√™u c·∫ßu. 
Sau ƒë√≥, ƒë·ªçc l∆∞·ªõt to√†n b·ªô **·∫¢NH B√ÄI L√ÄM** ƒë·ªÉ hi·ªÉu lu·ªìng t∆∞ duy t·ªïng th·ªÉ c·ªßa h·ªçc sinh TR∆Ø·ªöC KHI ƒëi v√†o chi ti·∫øt. 
ƒê·ª´ng v·ªôi v√†ng ph√°n x√©t ngay t·ª´ l·ªói sai ƒë·∫ßu ti√™n.
**B∆∞·ªõc 2: Ph√¢n t√≠ch Logic v√† T√¨m "L·ªói G·ªëc" (Root Cause Analysis)**
ƒê√¢y l√† b∆∞·ªõc quan tr·ªçng nh·∫•t. H√£y d√≤ theo t·ª´ng b∆∞·ªõc l·∫≠p lu·∫≠n c·ªßa h·ªçc sinh:
*   **H∆∞·ªõng ƒëi c√≥ ƒë√∫ng kh√¥ng?** H·ªçc sinh c√≥ ch·ªçn ƒë√∫ng ph∆∞∆°ng ph√°p, ƒë·ªãnh l√Ω, c√¥ng th·ª©c ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ kh√¥ng?
*   **Th·ª±c thi c√≥ ch√≠nh x√°c kh√¥ng?** Trong qu√° tr√¨nh bi·∫øn ƒë·ªïi, t√≠nh to√°n, h·ªçc sinh c√≥ m·∫Øc l·ªói kh√¥ng? (v√≠ d·ª•: chuy·ªÉn v·∫ø sai d·∫•u, t√≠nh to√°n sai, √°p d·ª•ng sai ƒëi·ªÅu ki·ªán).
*   **T√¨m L·ªói G·ªëc:** N·∫øu c√≥ nhi·ªÅu l·ªói sai, h√£y t·∫≠p trung v√†o **l·ªói sai ƒë·∫ßu ti√™n v√† c∆° b·∫£n nh·∫•t** ƒë√£ g√¢y ra chu·ªói sai l·∫ßm sau ƒë√≥. V√≠ d·ª•, n·∫øu h·ªçc sinh t√≠nh sai Delta ngay t·ª´ ƒë·∫ßu, d·∫´n ƒë·∫øn to√†n b·ªô ph·∫ßn t√¨m nghi·ªám ph√≠a sau ƒë·ªÅu sai, th√¨ "l·ªói g·ªëc" l√† "T√≠nh sai bi·ªát th·ª©c Delta".
*   **C√¥ng nh·∫≠n n·ªó l·ª±c:** N·∫øu h·ªçc sinh c√≥ h∆∞·ªõng ƒëi ƒë√∫ng nh∆∞ng g·∫∑p l·ªói t√≠nh to√°n nh·ªè, h√£y ghi nh·∫≠n ph·∫ßn t∆∞ duy ƒë√∫ng ƒë·∫Øn ƒë√≥.

### **TI√äU CH√ç ƒê√ÅNH GI√Å**
‚úÖ ƒê√öNG: Khi **ph∆∞∆°ng ph√°p + ƒë√°p √°n** ƒë·ªÅu ƒë√∫ng. L·ªùi gi·∫£i h·ª£p l√Ω v·ªÅ m·∫∑t to√°n h·ªçc, kh√¥ng ch·ª©a l·ªói logic nghi√™m tr·ªçng.
üîÑ ƒêI·ªÇM M·ªòT PH·∫¶N: Ph∆∞∆°ng ph√°p ƒë√∫ng ho·∫∑c ƒë√°p √°n ƒë√∫ng nh∆∞ng sai s√≥t nh·ªè trong t√≠nh to√°n, ho·∫∑c c√°c l·ªói kh√¥ng ƒë√°ng k·ªÉ.
‚ùå SAI: Ph∆∞∆°ng ph√°p sai ho·∫∑c ƒë√°p √°n sai ho·∫∑c ƒë√∫ng m·ªôt c√°ch "may m·∫Øn" nh∆∞ng c√≥ l·ªó h·ªïng logic nghi·ªám tr·ªçng.
‚ùå KH√îNG L√ÄM B√ÄI: B·ªè tr·ªëng ho·∫∑c b√†i l√†m kh√¥ng ƒë·ªçc ƒë∆∞·ª£c.

### **Y√äU C·∫¶U OUTPUT (B·∫ÆT BU·ªòC)**

B·∫°n ph·∫£i tr·∫£ v·ªÅ m·ªôt ƒë·ªëi t∆∞·ª£ng JSON duy nh·∫•t v·ªõi c·∫•u tr√∫c ch√≠nh x√°c nh∆∞ sau:

```json
{
  "is_correct": true/false,
  "confidence": float, (t·ª´ 0 ƒë·∫øn 1) #M·ª©c ƒë·ªô t·ª± tin c·ªßa Model khi ch·∫•m b√†i
  "error_description": "Gi·∫£i th√≠ch chi ti·∫øt v·ªÅ c√°c l·ªói", #N·∫øu ƒë√∫ng v√† kh√¥ng c√≥ l·ªói n√†o c·∫£ th√¨ tr·∫£ v·ªÅ NULL
  "error_phrases":"L·ªói sai h·ªçc sinh c·ª• th·ªÉ" (t·ªëi ƒëa 15 t·ª´ m·ªôt √Ω, t·ªëi ƒëa 3 √Ω) V√≠ d·ª•: ["M√¢u thu·∫´n logic: kh·∫≥ng ƒë·ªãnh (x-3)^2020+(2y+6)^2022>0 r·ªìi l·∫°i suy ra =0", "ƒê·∫∑t ƒëi·ªÅu ki·ªán cho ph∆∞∆°ng tr√¨nh ch·ª©a cƒÉn sai, ph·∫£i l√† ... ch·ª© kh√¥ng l√† ...",...]
  "partial_credit": true/false #Trong qu√° tr√¨nh l√†m b√†i t·ªìn t·∫°i nh·ªØng b∆∞·ªõc ƒë√∫ng (V√≠ d·ª• logic gi·∫£i b√†i g·ªìm 4 b∆∞·ªõc v√† ƒë√∫ng hai b∆∞·ªõc ƒë·∫ßu)
}
"""

    def __init__(self, api_key: str, model_name: str = "gpt-4o"):
        if not api_key:
            raise ValueError("OpenAI API key is required.")
        self.client = OpenAI(api_key=api_key)
        self.async_client = AsyncOpenAI(api_key=api_key)
        self.model_name = model_name
        logger.info(f"OpenAIModel initialized with model: {self.model_name}")

    def _encode_image(self, image_path: str) -> str:
        """Encode image to base64."""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            logger.error(f"Failed to encode image {image_path}: {e}")
            raise

    def _get_image_mime_type(self, image_path: str) -> str:
        """Determine MIME type from file extension."""
        ext = Path(image_path).suffix.lower()
        return {'.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png'}.get(ext, 'image/jpeg')

    def grade_image_pair(self, question_image_paths: List[str], answer_image_paths: List[str]) -> Dict[str, Any]:
        """
        Grades a student's answer by analyzing question and answer images using OpenAI's API.
        """
        logger.info(f"Grading with OpenAI: {len(question_image_paths)} question images vs {len(answer_image_paths)} answer images.")
        logger.info(f"Question image paths: {question_image_paths}")
        logger.info(f"Answer image paths: {answer_image_paths}")
        
        try:
            message_content = [{"type": "text", "text": "H√£y ch·∫•m b√†i t·ª± lu·∫≠n to√°n c·ªßa h·ªçc sinh."}]

            # Add question images
            for img_path in question_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Question image not found: {img_path}")
                b64_image = self._encode_image(img_path)
                mime_type = self._get_image_mime_type(img_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:{mime_type};base64,{b64_image}", "detail": "high"}
                })

            # Add answer images
            for img_path in answer_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Answer image not found: {img_path}")
                b64_image = self._encode_image(img_path)
                mime_type = self._get_image_mime_type(img_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:{mime_type};base64,{b64_image}", "detail": "high"}
                })

            messages = [
                {"role": "system", "content": self.VISION_GRADING_PROMPT},
                {"role": "user", "content": message_content}
            ]

            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_completion_tokens=5000,
                response_format={"type": "json_object"}
            )

            log_llm_call(response, self.model_name, SERVICE_VISION_GRADING)
            
            result_json = json.loads(response.choices[0].message.content)
            return result_json

        except json.JSONDecodeError as e:
            logger.error(f"OpenAI response JSON parsing failed: {e}")
            raise
        except Exception as e:
            logger.error(f"OpenAI grading failed: {e}")
            raise

    async def _grade_image_pair_async(self, question_image_paths: List[str], answer_image_paths: List[str]) -> Dict[str, Any]:
        """Async version of grade_image_pair for batch processing"""
        logger.info(f"Async grading with OpenAI: {len(question_image_paths)} question images vs {len(answer_image_paths)} answer images.")
        
        try:
            message_content = [{"type": "text", "text": "H√£y ch·∫•m b√†i t·ª± lu·∫≠n to√°n c·ªßa h·ªçc sinh."}]

            # Add question images
            for img_path in question_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Question image not found: {img_path}")
                b64_image = self._encode_image(img_path)
                mime_type = self._get_image_mime_type(img_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:{mime_type};base64,{b64_image}", "detail": "high"}
                })

            # Add answer images
            for img_path in answer_image_paths:
                if not os.path.exists(img_path):
                    raise FileNotFoundError(f"Answer image not found: {img_path}")
                b64_image = self._encode_image(img_path)
                mime_type = self._get_image_mime_type(img_path)
                message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:{mime_type};base64,{b64_image}", "detail": "high"}
                })

            messages = [
                {"role": "system", "content": self.VISION_GRADING_PROMPT},
                {"role": "user", "content": message_content}
            ]

            response = await self.async_client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_completion_tokens=5000,
                response_format={"type": "json_object"}
            )

            log_llm_call(response, self.model_name, SERVICE_VISION_GRADING)
            
            result_json = json.loads(response.choices[0].message.content)
            return result_json

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON response: {e}")
            return {"is_correct": False, "confidence": 0.0, "error_description": "Failed to parse AI response", "error_phrases": [], "partial_credit": False}
        except Exception as e:
            logger.error(f"Async API request failed: {e}")
            return {"is_correct": False, "confidence": 0.0, "error_description": f"API error: {str(e)}", "error_phrases": [], "partial_credit": False}

    def grade_batch(self, items: List[Dict]) -> List[Dict[str, Any]]:
        """Override base method to use async processing with concurrency limit"""
        if not items:
            return []
            
        logger.info(f"Starting async batch grading for {len(items)} items with max 10 concurrent requests")
        return asyncio.run(self._grade_batch_async(items))
    
    async def _grade_batch_async(self, items: List[Dict]) -> List[Dict[str, Any]]:
        """Async batch processing with concurrency limit"""
        semaphore = asyncio.Semaphore(10)  # Max 10 concurrent requests
        
        async def process_item(item):
            async with semaphore:
                return await self._grade_image_pair_async(
                    question_image_paths=item['question_image_paths'],
                    answer_image_paths=item['answer_image_paths']
                )
        
        tasks = [process_item(item) for item in items]
        results = await asyncio.gather(*tasks)
        
        logger.info(f"Async batch grading completed for {len(items)} items")
        return results